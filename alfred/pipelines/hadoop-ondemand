job {
    // Name of the pipeline to be created
    name = "hadoop-ondemand-thunderX"

    // Type of pipeline periodic, on-demand and per-commit
    pipeline_type = "on-demand"

    // Variables for on-demand pipeline.
    ondemand_variables = "HADOOP_BRANCH=master; HIBENCH_VERSION=6.0 ;JAVA_VERSION=8,9;PROTOBUF_VERSION=2.5.0;DFS_REPLICAS=1;SCALA_VERSION= 2.12.1"

    // Name of Workload
    workload = "hadoop"

    // Repos to be cloned for the pipeline
    clone_repos = "ats"

    // Agents to be assigned to the pipeline
    label = "hadoop_agents"

    // Scripts to be run in different stages
    stage1_bootstrap      = "./common/bootstrap.sh --workload hadoop"
    stage2_PreRunCleanup  = "./common/cleanup.sh --workload hadoop --soft"
    stage3_BuildHadoop    = "./common/stage.sh --workload hadoop --name build_hadoop"
    stage4_SetupHadoop    = "./common/stage.sh --workload hadoop --name setup_hadoop"
    stage5_BuildHibench   = "./common/stage.sh --workload hadoop --name build_hibench"
    stage6_SetupHibench   = "./common/stage.sh --workload hadoop --name setup_hibench"
    stage7_RunTests       = "./hadoop/tests/run_tests.sh"
    stage8_PostRunCleanup = "./common/cleanup.sh --workload hadoop --soft"

    // Alert build status of each job on specified email address
    email = ""

    // Common logs aggregation location for the job
    artifacts = "logs/"
}
